{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dress-auditor",
   "metadata": {},
   "source": [
    "# Pràctica 4 PLN: pre-processat de text i extracció de característiques\n",
    "En aquesta pràctica realitzarem la neteja i pre-processat de diferents conjunts de dades de text.\\\n",
    "Després farem una extracció de característiques com a matriu *sparse* i com a vectors de paraules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "prime-fever",
   "metadata": {},
   "source": [
    "### Noms:\n",
    "Introdueix en aquesta cel·la els noms dels dos integrants del grup:\\\n",
    "*Alumne 1* \\\n",
    "*Alumne 2*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "following-weapon",
   "metadata": {},
   "source": [
    "## Part 1: conjunt de textos de \"mundocine\"\n",
    "En aquest primer conjunt de dades tenim una sèrie de crítiques de pel·lícules de cinema, emmagatzemades en format XML (una crítica per arxiu). Hem preparat una funció de tipus `generator` que processa el directori on estan els arxius de les crítiques i retorna per cada arxiu XML una tupla amb 4 valors:\n",
    " - Nom de la pel·lícula (string)\n",
    " - Resum breu de la crítica (string)\n",
    " - Text de la crítica (*string*)\n",
    " - Valoració de la pel·lícula (*int* d'1 a 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "wireless-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from xml.dom.minidom import parseString\n",
    "\n",
    "def parse_folder(path):\n",
    "    \"\"\"generator that reads the contents of XML files in a folder\n",
    "    Returns the <body> of the <review> in each XML file.\n",
    "    XML files encoded as 'latin-1'\"\"\"\n",
    "    for file in sorted([f for f in os.listdir(path) if f.endswith('.xml')],\n",
    "                        key=lambda x: int(re.match(r'\\d+',x).group())):\n",
    "        with open(os.path.join(path, file), encoding='latin-1') as f:\n",
    "            doc=parseString(f.read())\n",
    "\n",
    "            titulo = doc.documentElement.attributes[\"title\"].value\n",
    "\n",
    "            btxt = \"\"\n",
    "            review_bod = doc.getElementsByTagName(\"body\")\n",
    "            if len(review_bod) > 0:\n",
    "                for node in review_bod[0].childNodes:\n",
    "                    if node.nodeType == node.TEXT_NODE:\n",
    "                        btxt += node.data + \" \"\n",
    "\n",
    "            rtxt = \"\"\n",
    "            review_summ = doc.getElementsByTagName(\"summary\")\n",
    "            if len(review_summ) > 0:\n",
    "                for node in review_summ[0].childNodes:\n",
    "                    if node.nodeType == node.TEXT_NODE:\n",
    "                        rtxt += node.data + \" \"\n",
    "                        \n",
    "            rank = int(doc.documentElement.attributes[\"rank\"].value)\n",
    "            \n",
    "            yield titulo, rtxt, btxt, rank\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "automotive-gentleman",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Les crítiques es troben en el directori \"critiques\" (si no tens el directori, descomprimeix l'arxiu \"critiques.zip\" que s'entrega en el material de la pràctica. \\\n",
    "Càrrega la primera crítica del directori usant el mètode `next` sobre la funció `parse_folder` en l'objecte `critica`. Mostra els seus 4 valors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "median-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La guerra de los mundos'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critica = next(parse_folder(\"criticas\"))\n",
    "critica[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "excellent-guitar",
   "metadata": {},
   "source": [
    "## Anàlisi exploratòria\n",
    "Abans de processar el text calcularem una sèrie de paràmetres de cada crítica. \\\n",
    "Per a això processem cada crítica per a i guardarem els resultats en un objecte `DataFrame` de Colles.\\\n",
    "Com a característica de cada crítica extraurem:\n",
    "- Títol de la pel·lícula\n",
    "- Longitud (en caràcters) del resum\n",
    "- Longitud (en caràcters) del text de la crítica\n",
    "- Puntuació de la crítica\n",
    "\n",
    "### Exercici\n",
    "Completa el codi següent per a generar el `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fancy-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#creamos una lista en blanco\n",
    "datos = list()\n",
    "\n",
    "#recorremos las críticas y calculamos sus métricas\n",
    "for c in parse_folder(\"criticas\"):\n",
    "    datos.append({\n",
    "        'título': c[0],\n",
    "        'LongResumen': len(c[1]),\n",
    "        'LongCritica': len(c[2]),\n",
    "        'puntuación': c[3]\n",
    "    })\n",
    "\n",
    "resumen = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "outdoor-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>título</th>\n",
       "      <th>LongResumen</th>\n",
       "      <th>LongCritica</th>\n",
       "      <th>puntuación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La guerra de los mundos</td>\n",
       "      <td>32</td>\n",
       "      <td>2951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stars Wars III La venganza de los Sith</td>\n",
       "      <td>30</td>\n",
       "      <td>3954</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Increibles</td>\n",
       "      <td>68</td>\n",
       "      <td>2467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiderman 2</td>\n",
       "      <td>45</td>\n",
       "      <td>3403</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La casa de cera</td>\n",
       "      <td>42</td>\n",
       "      <td>1696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>El internado</td>\n",
       "      <td>31</td>\n",
       "      <td>1163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La llave del mal</td>\n",
       "      <td>36</td>\n",
       "      <td>1781</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>May</td>\n",
       "      <td>28</td>\n",
       "      <td>3343</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cinderella Man</td>\n",
       "      <td>33</td>\n",
       "      <td>2885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>La Novia Cadaver</td>\n",
       "      <td>40</td>\n",
       "      <td>736</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Harry poter y el caliz de fuego</td>\n",
       "      <td>47</td>\n",
       "      <td>5127</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Match point</td>\n",
       "      <td>19</td>\n",
       "      <td>2847</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>King Kong</td>\n",
       "      <td>12</td>\n",
       "      <td>2623</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El jardinero fiel</td>\n",
       "      <td>43</td>\n",
       "      <td>2078</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Doom</td>\n",
       "      <td>25</td>\n",
       "      <td>1790</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Las cronicas de Narnia</td>\n",
       "      <td>55</td>\n",
       "      <td>1451</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Una historia violenta</td>\n",
       "      <td>32</td>\n",
       "      <td>981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Saw 2</td>\n",
       "      <td>50</td>\n",
       "      <td>3886</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Crash</td>\n",
       "      <td>30</td>\n",
       "      <td>1478</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jarhead</td>\n",
       "      <td>69</td>\n",
       "      <td>3413</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Memorias de una Geisha</td>\n",
       "      <td>71</td>\n",
       "      <td>2597</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brokeback mountain</td>\n",
       "      <td>70</td>\n",
       "      <td>5027</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alone in the dark</td>\n",
       "      <td>57</td>\n",
       "      <td>1519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Munich</td>\n",
       "      <td>45</td>\n",
       "      <td>4669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Terror en la niebla</td>\n",
       "      <td>37</td>\n",
       "      <td>4637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Secretos de familia</td>\n",
       "      <td>52</td>\n",
       "      <td>1541</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Underworld evolution</td>\n",
       "      <td>75</td>\n",
       "      <td>1579</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lutero</td>\n",
       "      <td>69</td>\n",
       "      <td>3083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Camaron</td>\n",
       "      <td>22</td>\n",
       "      <td>1448</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    título  LongResumen  LongCritica  \\\n",
       "0                  La guerra de los mundos           32         2951   \n",
       "1   Stars Wars III La venganza de los Sith           30         3954   \n",
       "2                           Los Increibles           68         2467   \n",
       "3                              Spiderman 2           45         3403   \n",
       "4                          La casa de cera           42         1696   \n",
       "5                             El internado           31         1163   \n",
       "6                         La llave del mal           36         1781   \n",
       "7                                      May           28         3343   \n",
       "8                           Cinderella Man           33         2885   \n",
       "9                         La Novia Cadaver           40          736   \n",
       "10         Harry poter y el caliz de fuego           47         5127   \n",
       "11                             Match point           19         2847   \n",
       "12                               King Kong           12         2623   \n",
       "13                       El jardinero fiel           43         2078   \n",
       "14                                    Doom           25         1790   \n",
       "15                  Las cronicas de Narnia           55         1451   \n",
       "16                   Una historia violenta           32          981   \n",
       "17                                   Saw 2           50         3886   \n",
       "18                                   Crash           30         1478   \n",
       "19                                 Jarhead           69         3413   \n",
       "20                  Memorias de una Geisha           71         2597   \n",
       "21                      Brokeback mountain           70         5027   \n",
       "22                       Alone in the dark           57         1519   \n",
       "23                                  Munich           45         4669   \n",
       "24                     Terror en la niebla           37         4637   \n",
       "25                     Secretos de familia           52         1541   \n",
       "26                    Underworld evolution           75         1579   \n",
       "27                                  Lutero           69         3083   \n",
       "28                                 Camaron           22         1448   \n",
       "\n",
       "    puntuación  \n",
       "0            1  \n",
       "1            3  \n",
       "2            5  \n",
       "3            2  \n",
       "4            2  \n",
       "5            2  \n",
       "6            3  \n",
       "7            4  \n",
       "8            2  \n",
       "9            3  \n",
       "10           4  \n",
       "11           5  \n",
       "12           5  \n",
       "13           4  \n",
       "14           3  \n",
       "15           3  \n",
       "16           2  \n",
       "17           3  \n",
       "18           3  \n",
       "19           5  \n",
       "20           3  \n",
       "21           2  \n",
       "22           1  \n",
       "23           2  \n",
       "24           1  \n",
       "25           2  \n",
       "26           3  \n",
       "27           2  \n",
       "28           3  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cordless-combat",
   "metadata": {},
   "source": [
    "## Neteja de text\n",
    "Prepararem aquest conjunt de textos per a entrenar un model per a predir la puntuació de cada crítica a partir del text de la crítica.\\\n",
    "Realitzarem el següent processament:\n",
    "- Separar el text en *tokens*\n",
    "- Eliminar els *tokens* de tipus *stop-word*, signes de puntuació o espais\n",
    "- Convertir les entitats de tipus `PER` al token *persona*\n",
    "- Lematizar el text\n",
    "\n",
    "### Exercici\n",
    "Completa el codi següent per a realitzar aquestes funcions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "decreased-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "#definimos función de normalizado\n",
    "def normaliza(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = [t for t in doc if not t.is_punct and not t.is_space and not t.is_stop] #devuelve los tokens que cumplen las condiciones\n",
    "    palabras = []\n",
    "    for t in tokens:\n",
    "        if t.ent_iob_=='B' and t.ent_type_=='PER':\n",
    "            palabras.append('persona')\n",
    "        elif t.ent_iob_=='I' and t.ent_type_=='PER':\n",
    "            continue\n",
    "        else:\n",
    "            palabras.append(t.lemma_) #si no es PER añadimos el lema\n",
    "    salida = ' '.join(palabras) #junta todos los tokens en un string\n",
    "    \n",
    "    return salida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "injured-softball",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament en la crítica prèviament descarregada (variable `critica`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "wicked-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gustar cine masa pelicula ver mundo parecer coñazo insufribl porqué prota tonto culo suerte peli lograr vencer convertir listo chorrada comienzo pelicula esfumar arte magia volver maduro inteligente peli Spielberg huir huir dar tiro cabron meter par actor echar él comer aparte niña viejo metido cuerpo niña ver él hablar version original dar él freaks cine creerar gracia nena puta madre causar pavor cria persona maduro horroroso niño niño ver él rol asustar hijo adolescente Cruise subnormal dar él bofetada ver hueso mano persona reflejo denominar manipulacion militar chico matar bicho ningun arma persona loco pensar venir saco quereis decir fanatismo locura alguien querer luchar medio muerte seguro jodar sobremanera pelicula aparecer mongo abuelo familia salir dios viejo aparecer traje domingo maquillada.¿pero sinsorgado faltar persona volver exmujer mundo tranquilos contar peli pasar peli acabar restar misterio bodrio persona paso convertir director efecto especial contar historias?¿no distei norteamericano guardar compostura gritar momento dificil sensato tranquilizar él discutir chorrada puta peli parar gritar pegar él gracia comienzo peli suelo empezar resquebrajar él gente quedar mirar pasar persona estaria correr puta tiempo escondiéndome ver bicho lanzar rayo machacar to dios esconder seguir hablar mierda queriar conseguir pagasemos entrada cine prima bajarir internet ver calidad peli aceptable pasar él palante mando forward mano morir'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliza(critica[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beneficial-arkansas",
   "metadata": {},
   "source": [
    "### Possibles millores sobre el processament\n",
    "Observem els següents problemes:\n",
    "- Algunes paraules no se separen correctament perquè en el text original estan unides per signes de puntuació.\n",
    "- La llista de *stop-words* de spaCy no conté 'a','e','i'.\n",
    "- Alguns lemes mantenen les majúscules.\\\n",
    "\n",
    "Redefinim la funció de normalització per a corregir això:\n",
    "- Introduïm un espai després de determinats signes de puntuació (\".\", \"?\") perquè la divisió en tokens siga correcta\n",
    "- Filtrem els *tokens* amb una longitud d'1\n",
    "- Passem a minúscules el lema de cada token\n",
    "\n",
    "Completa la funció per a realitzar aquestes correccions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "turned-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_bis(texto):\n",
    "    texto = re.sub(r\"([?.])\", r\"\\1 \", texto) #añadimos un espacio después de \".\" y \"?\"\n",
    "    doc = nlp(texto)\n",
    "    tokens = [t for t in doc if not t.is_punct and not t.is_space and not t.is_stop and len(t) > 1] #filtramos los tokens que nos interesan\n",
    "    palabras = []\n",
    "    for t in tokens:\n",
    "        if t.ent_iob_=='B' and t.ent_type_=='PER':\n",
    "            palabras.append('persona')\n",
    "        elif t.ent_iob_=='I' and t.ent_type_=='PER':\n",
    "            continue\n",
    "        else:\n",
    "            palabras.append(t.lemma_.lower()) #añadimos lema en minúsculas\n",
    "    salida = ' '.join(palabras) #junta todos los tokens en un string\n",
    "    \n",
    "    return salida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "younger-running",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament en la crítica prèviament descarregada (variable `critica`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "economic-serve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gustar cine masa pelicula ver mundo parecer coñazo insufribl porqué prota tonto culo suerte peli lograr vencer convertir listo chorrada comienzo pelicula esfumar arte magia volver maduro inteligente peli spielberg huir huir dar tiro cabron meter par actor echar él comer aparte niña viejo metido cuerpo niña ver él hablar version original dar él freaks cine creerar gracia nena puta madre causar pavor cria persona maduro horroroso niño niño ver él rol asustar hijo adolescente cruise subnormal dar él bofetada ver hueso mano persona reflejo denominar manipulacion militar chico matar bicho ningun arma persona loco pensar venir saco quereis decir fanatismo locura alguien querer luchar medio muerte seguro jodar sobremanera pelicula aparecer mongo abuelo familia salir dios viejo aparecer traje domingo maquillada sinsorgado faltar persona volver exmujer mundo tranquilos contar peli pasar peli acabar restar misterio bodrio persona paso convertir director efecto especial contar historia disteis norteamericano guardar compostura gritar momento dificil sensato tranquilizar él discutir chorrada puta peli parar gritar pegar él gracia comienzo peli suelo empezar resquebrajar él gente quedar mirar pasar persona estaria correr puta tiempo escondiéndome ver bicho lanzar rayo machacar to dios esconder seguir hablar mierda queriar conseguir pagasemos entrada cine prima bajarir internet ver calidad peli aceptable pasar él palante mando forward mano morir'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normaliza_bis(critica[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "funny-parcel",
   "metadata": {},
   "source": [
    "### Anàlisi morfològica\n",
    "En una crítica té molta importància els adjectius utilitzats.\\\n",
    "Crea una funció per a filtrar només els adjectius utilitzats en cada crítica (utilitza el lema de cada adjectiu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "special-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_adj(texto):\n",
    "    texto = re.sub(r'([?.])', r'\\1 ', texto) #separamos . y ?\n",
    "    doc = nlp(texto)\n",
    "    tokens = [t.lemma_ for t in doc if t.pos_=='ADJ']\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1e902",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament en la crítica prèviament descarregada (variable `critica`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "immune-sauce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'insufribl chorrada maduro inteligente solo viejo metido original claro grande igual maduro horroroso adolescente subnormal militar loco seguro viejo sinsorgado solo mejor igual bueno especial dificil sensato chorrada aceptable'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraer_adj(critica[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "limited-integrity",
   "metadata": {},
   "source": [
    "### Processament de tot el conjunt de dades\n",
    "Aplicarem aquestes funcions en bloc a tot el conjunt de dades. \\\n",
    "En aquesta ocasió, no farem res amb el text normalitzat sinó que només ho aplicarem per a calcular el núm. de paraules i el núm. d'adjectius de cada crítica.\n",
    "\n",
    "### Exercici\n",
    "Completa el codi següent:\\\n",
    "Nota: tingues en compte que per a comptar paraules has de dividir el *string* en espais i comptar el núm. d'elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "least-indication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>título</th>\n",
       "      <th>LongResumen</th>\n",
       "      <th>LongCritica</th>\n",
       "      <th>NumPalabras</th>\n",
       "      <th>NumAdj</th>\n",
       "      <th>puntuación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La guerra de los mundos</td>\n",
       "      <td>7</td>\n",
       "      <td>569</td>\n",
       "      <td>210</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stars Wars III La venganza de los Sith</td>\n",
       "      <td>9</td>\n",
       "      <td>762</td>\n",
       "      <td>277</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Increibles</td>\n",
       "      <td>12</td>\n",
       "      <td>464</td>\n",
       "      <td>166</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiderman 2</td>\n",
       "      <td>10</td>\n",
       "      <td>653</td>\n",
       "      <td>255</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La casa de cera</td>\n",
       "      <td>8</td>\n",
       "      <td>314</td>\n",
       "      <td>122</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>El internado</td>\n",
       "      <td>7</td>\n",
       "      <td>210</td>\n",
       "      <td>81</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La llave del mal</td>\n",
       "      <td>9</td>\n",
       "      <td>319</td>\n",
       "      <td>118</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>May</td>\n",
       "      <td>6</td>\n",
       "      <td>565</td>\n",
       "      <td>223</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cinderella Man</td>\n",
       "      <td>7</td>\n",
       "      <td>493</td>\n",
       "      <td>189</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>La Novia Cadaver</td>\n",
       "      <td>8</td>\n",
       "      <td>130</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Harry poter y el caliz de fuego</td>\n",
       "      <td>8</td>\n",
       "      <td>877</td>\n",
       "      <td>361</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Match point</td>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "      <td>198</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>King Kong</td>\n",
       "      <td>4</td>\n",
       "      <td>480</td>\n",
       "      <td>190</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El jardinero fiel</td>\n",
       "      <td>8</td>\n",
       "      <td>335</td>\n",
       "      <td>156</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Doom</td>\n",
       "      <td>6</td>\n",
       "      <td>318</td>\n",
       "      <td>112</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Las cronicas de Narnia</td>\n",
       "      <td>11</td>\n",
       "      <td>252</td>\n",
       "      <td>91</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Una historia violenta</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Saw 2</td>\n",
       "      <td>12</td>\n",
       "      <td>646</td>\n",
       "      <td>279</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Crash</td>\n",
       "      <td>7</td>\n",
       "      <td>261</td>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jarhead</td>\n",
       "      <td>11</td>\n",
       "      <td>579</td>\n",
       "      <td>245</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Memorias de una Geisha</td>\n",
       "      <td>13</td>\n",
       "      <td>454</td>\n",
       "      <td>166</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brokeback mountain</td>\n",
       "      <td>14</td>\n",
       "      <td>853</td>\n",
       "      <td>341</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alone in the dark</td>\n",
       "      <td>11</td>\n",
       "      <td>267</td>\n",
       "      <td>107</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Munich</td>\n",
       "      <td>6</td>\n",
       "      <td>747</td>\n",
       "      <td>355</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Terror en la niebla</td>\n",
       "      <td>7</td>\n",
       "      <td>827</td>\n",
       "      <td>289</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Secretos de familia</td>\n",
       "      <td>11</td>\n",
       "      <td>272</td>\n",
       "      <td>111</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Underworld evolution</td>\n",
       "      <td>15</td>\n",
       "      <td>278</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lutero</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>214</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Camaron</td>\n",
       "      <td>6</td>\n",
       "      <td>264</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    título  LongResumen  LongCritica  \\\n",
       "0                  La guerra de los mundos            7          569   \n",
       "1   Stars Wars III La venganza de los Sith            9          762   \n",
       "2                           Los Increibles           12          464   \n",
       "3                              Spiderman 2           10          653   \n",
       "4                          La casa de cera            8          314   \n",
       "5                             El internado            7          210   \n",
       "6                         La llave del mal            9          319   \n",
       "7                                      May            6          565   \n",
       "8                           Cinderella Man            7          493   \n",
       "9                         La Novia Cadaver            8          130   \n",
       "10         Harry poter y el caliz de fuego            8          877   \n",
       "11                             Match point            4          484   \n",
       "12                               King Kong            4          480   \n",
       "13                       El jardinero fiel            8          335   \n",
       "14                                    Doom            6          318   \n",
       "15                  Las cronicas de Narnia           11          252   \n",
       "16                   Una historia violenta            5          164   \n",
       "17                                   Saw 2           12          646   \n",
       "18                                   Crash            7          261   \n",
       "19                                 Jarhead           11          579   \n",
       "20                  Memorias de una Geisha           13          454   \n",
       "21                      Brokeback mountain           14          853   \n",
       "22                       Alone in the dark           11          267   \n",
       "23                                  Munich            6          747   \n",
       "24                     Terror en la niebla            7          827   \n",
       "25                     Secretos de familia           11          272   \n",
       "26                    Underworld evolution           15          278   \n",
       "27                                  Lutero           11          519   \n",
       "28                                 Camaron            6          264   \n",
       "\n",
       "    NumPalabras  NumAdj  puntuación  \n",
       "0           210      29           1  \n",
       "1           277      50           3  \n",
       "2           166      33           5  \n",
       "3           255      37           2  \n",
       "4           122      23           2  \n",
       "5            81      20           2  \n",
       "6           118      23           3  \n",
       "7           223      59           4  \n",
       "8           189      46           2  \n",
       "9            48       6           3  \n",
       "10          361      83           4  \n",
       "11          198      46           5  \n",
       "12          190      38           5  \n",
       "13          156      33           4  \n",
       "14          112      19           3  \n",
       "15           91      23           3  \n",
       "16           75      15           2  \n",
       "17          279      49           3  \n",
       "18           96      18           3  \n",
       "19          245      44           5  \n",
       "20          166      41           3  \n",
       "21          341      80           2  \n",
       "22          107      15           1  \n",
       "23          355      86           2  \n",
       "24          289      71           1  \n",
       "25          111      24           2  \n",
       "26           94      23           3  \n",
       "27          214      45           2  \n",
       "28          101      20           3  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creamos una lista en blanco\n",
    "datos = []\n",
    "\n",
    "#recorremos las críticas y calculamos sus métricas\n",
    "for c in parse_folder(\"criticas\"):\n",
    "    datos.append({\n",
    "        'título': c[0],\n",
    "        'LongResumen': len(c[1].split(' ')),\n",
    "        'LongCritica': len(c[2].split(' ')),\n",
    "        'NumPalabras': len(normaliza_bis(c[2]).split(' ')),\n",
    "        'NumAdj': len(extraer_adj(c[2]).split(' ')),\n",
    "        'puntuación': c[3]\n",
    "    })\n",
    "\n",
    "resumen = pd.DataFrame(datos)\n",
    "resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "laden-special",
   "metadata": {},
   "source": [
    "## Part 2: Extracció de característiques *sparse*\n",
    "Anem a calcules les matrius de característiques *bag-of-words* i *tfidf* del conjunt de textos anterior.\\\n",
    "Usarem la llibreria `scikit-learn` per a vectorizar els documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "critical-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para no tener que cargar todas las críticas en memoria,\n",
    "#creamos un generador que devuelve iterativamente el\n",
    "#texto procesado de cada crítica\n",
    "\n",
    "def generaCritica(criticas):\n",
    "    \"\"\"Función de tipo generator que devuelve el\n",
    "    texto normalizado de cada crítica.\n",
    "    Entrada:\n",
    "    criticas: objeto 'parse_folder' que itera\n",
    "    sobre el directio de las críticas\n",
    "    Salida:\n",
    "    texto normalizado de cada crítica\"\"\"\n",
    "    for c in criticas:\n",
    "        yield normaliza_bis(c[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "young-receptor",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament generant el text normalitzat de la primera crítica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "arbitrary-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gustar cine masa pelicula ver mundo parecer coñazo insufribl porqué prota tonto culo suerte peli lograr vencer convertir listo chorrada comienzo pelicula esfumar arte magia volver maduro inteligente peli spielberg huir huir dar tiro cabron meter par actor echar él comer aparte niña viejo metido cuerpo niña ver él hablar version original dar él freaks cine creerar gracia nena puta madre causar pavor cria persona maduro horroroso niño niño ver él rol asustar hijo adolescente cruise subnormal dar él bofetada ver hueso mano persona reflejo denominar manipulacion militar chico matar bicho ningun arma persona loco pensar venir saco quereis decir fanatismo locura alguien querer luchar medio muerte seguro jodar sobremanera pelicula aparecer mongo abuelo familia salir dios viejo aparecer traje domingo maquillada sinsorgado faltar persona volver exmujer mundo tranquilos contar peli pasar peli acabar restar misterio bodrio persona paso convertir director efecto especial contar historia disteis norteamericano guardar compostura gritar momento dificil sensato tranquilizar él discutir chorrada puta peli parar gritar pegar él gracia comienzo peli suelo empezar resquebrajar él gente quedar mirar pasar persona estaria correr puta tiempo escondiéndome ver bicho lanzar rayo machacar to dios esconder seguir hablar mierda queriar conseguir pagasemos entrada cine prima bajarir internet ver calidad peli aceptable pasar él palante mando forward mano morir'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generaCritica(parse_folder('criticas')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adjusted-administration",
   "metadata": {},
   "source": [
    "Vectorizem tot el conjunt de dades usant les funcions de `scikit-learn`.\\\n",
    "Aquestes funcions admeten un objecte `generator` com a argument d'entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "collective-publisher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "\n",
    "criticas = generaCritica(parse_folder('criticas'))#creamos el objeto generador\n",
    "\n",
    "BoW_criticas = vect.fit(list(criticas))\n",
    "BoW_criticas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stock-wings",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Genera diferents variants de matrius de característiques per al conjunt de les crítiques. Prova amb:\n",
    "- Matriu TF-IDF\n",
    "- Matriu BoW amb unigrames i bigrames\n",
    "- Matriu TF-IDF eliminant les paraules menys freqüents i les més freqüents (mínim de 2 i màxim de 5 documents)\n",
    "- Mostra quines són les paraules més freqüents eliminades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "southern-dealer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 2508)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(norm=None, use_idf=True)\n",
    "criticas = generaCritica(parse_folder('criticas'))\n",
    "tv_matrix = tv.fit_transform(list(criticas))\n",
    "tv_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz BoW con unigramas y bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz TF-IDF con min_df=1 y max_df=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras más frecuentes a eliminar\n",
    "#aparecen en el atributo 'stop_words_' del vectorizador"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "primary-intention",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "Ara calcularem els *word vectors* de les paraules del nostre conjunt de dades, usant la classe `word2vec` de la llibreria `gensim`.\\\n",
    "Aquesta llibreria accepta com a argument d'entrada un objecte `iterador` que generarà el text pre-processament de la següent crítica en la seqüència.\\\n",
    "Usarem les funcions de pre-processament de la llibreria `gensim`.\\\n",
    "Primer definim un objecte de tipus `iterator` per a recórrer les crítiques. Es diferencia d'un simple `generator` que es pot reiniciar la generació de la seqüència (necessari per al model `word2vec`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "        \n",
    "class PreprocesaCriticas(object):\n",
    "    \"\"\"Pre-procesa el corpus de críticas con la función 'simple_preprocess'\n",
    "    de la librería gensim\n",
    "    Entrada: directorio de críticas\n",
    "    Salida: iterador sobre las críticas (como lista de tokens)\"\"\"\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for c in parse_folder(self.dirname):\n",
    "            yield simple_preprocess(c[2], deacc=True, min_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciamos un objeto para nuestro directorio\n",
    "criticas = PreprocesaCriticas(____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pending-passion",
   "metadata": {},
   "source": [
    "Per a provar el seu funcionament amb la primera crítica el convertim en iterable i usem el mètode `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "realistic-holiday",
   "metadata": {},
   "source": [
    "Al contrari que l'objecte generat amb la funció `generaCriticas` l'objecte de `PreprocesaCriticas` es reinicia cada vegada que iterem. \\\n",
    "Calculem els vectors de paraules de tot el corpus amb el model `word2vec` que accepta com a argument d'entrada un objecte de tipus `iterator` com el creat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cálculo de los vectores de palabras\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(___, #iterador con los documentos\n",
    "                               size=10,          #tamaño del vector\n",
    "                               window=5,         #nº de términos adyacentes que usamos para el cálculo\n",
    "                               min_count=5,      #nº mínimo de apariciones del término para contarlo\n",
    "                               iter=100\n",
    "                              )\n",
    "\n",
    "#una vez entrenado el modelo nos quedamos con los vectores calculados\n",
    "#si no se van a actualizar los vectores con nuevos documentos\n",
    "model = model.wv\n",
    "len(model.vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "chronic-greensboro",
   "metadata": {},
   "source": [
    "Seleccionem aleatòriament 25 paraules del conjunt calculat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "palabras_sample = np.random.choice(model.index2word, 25, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "superb-terry",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Comprova com funciona el model buscant les paraules més similars semànticament a \"trama\", \"peli\" i \"pelicula\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras similares a 'trama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras similares a 'peli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras similares a 'pelicula'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "circular-wheat",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Veurem la influència del preprocessament. Per a això alimentarem el model amb les crítiques *preprocesadas amb la funció de normalització sobre `spaCy` (que produeix text lematizat i amb un altre filtrat).\\\n",
    "Per a això cal re-definir l'objecte `iterador` sobre el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparamos con un modelo que use el preprocesado de spaCy\n",
    "        \n",
    "class PreprocesaCriticasSpacy(object):\n",
    "    \"\"\"Pre-procesa el corpus de críticas con la función de normalización\n",
    "    definida con la librería spaCy\n",
    "    Entrada: directorio de críticas\n",
    "    Salida: iterador sobre las críticas (como lista de tokens)\"\"\"\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for c in parse_folder(self.dirname):\n",
    "            yield ________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pointed-vault",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Instància aquesta nova classe per al directori de les crítiques en l'objecte `critiques_spacy` i comprova el seu funcionament sobre la primera crítica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticas_spacy = PreprocesaCriticasSpacy(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba a generar la primera crítica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "furnished-serial",
   "metadata": {},
   "source": [
    "Calcula el model de vectors de paraules amb aquest nou *pre-processat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSpacy = Word2Vec(_____, #iterador con los documentos\n",
    "                               size=10,          #tamaño del vector\n",
    "                               window=5,         #nº de términos adyacentes que usamos para el cálculo\n",
    "                               min_count=5,      #nº mínimo de apariciones del término para contarlo\n",
    "                               iter=100\n",
    "                              )\n",
    "\n",
    "#una vez entrenado el modelo nos quedamos con los vectores calculados\n",
    "#si no se van a actualizar los vectores con nuevos documentos\n",
    "modelSpacy = modelSpacy.wv\n",
    "len(modelSpacy.vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "weighted-bracelet",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "per què el nou model té un vocabulari amb molts menys termes que el model anterior?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sound-drawing",
   "metadata": {},
   "source": [
    "### Visualització de word vectors\n",
    "Usem una reducció de dimensionalitat t-SNE per a visualitzar un grup de paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "palabras_vectors = model[model.index2word]\n",
    "\n",
    "#seleccinamos unos pocos términos para visualizarlos entre el conjunto\n",
    "random_idx = np.random.randint(len(model.index2word), size=5)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=250, perplexity=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(palabras_vectors)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='steelblue', alpha=0.1)\n",
    "\n",
    "labels = np.array(model.index2word)[random_idx]\n",
    "\n",
    "\n",
    "T_labels = T[random_idx,:]\n",
    "\n",
    "plt.scatter(T_labels[:, 0], T_labels[:, 1], c='lime', edgecolors='darkgreen')\n",
    "for label, x, y in zip(labels, T_labels[:, 0], T_labels[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "advance-success",
   "metadata": {},
   "source": [
    "Ara carregarem els vectors per a les mateixes paraules amb el model pre-entrenat GloVe de `spaCy` per a comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_vectors = [nlp.vocab[t].vector for t in model.index2word]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=250, perplexity=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(palabras_vectors)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='steelblue', alpha=0.1)\n",
    "\n",
    "labels = np.array(model.index2word)[random_idx]\n",
    "\n",
    "\n",
    "T_labels = T[random_idx,:]\n",
    "\n",
    "plt.scatter(T_labels[:, 0], T_labels[:, 1], c='lime', edgecolors='darkgreen')\n",
    "for label, x, y in zip(labels, T_labels[:, 0], T_labels[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "outdoor-flight",
   "metadata": {},
   "source": [
    "## Part 3: Conjunt de Tuits en espanyol\n",
    "Anem a pre-processar un conjunt de tuits en espanyol etiquetatges amb la seua polaritat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Leemos los datos\n",
    "df = pd.read_csv('tweets_all.csv', index_col=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "incredible-boating",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Defineix una funció de normalització que faça les següents tasques:\n",
    "- Eliminar esments i URL mitjançant un patró RegEx\n",
    "- Separar el text en *tokens* convertint-los a minúscules, eliminant els que siguen signes de puntuació, espais o dígits\n",
    "- Eliminar els stop-words d'una llista pròpia passada com a argument\n",
    "- Eliminar els símbols de puntuació dels tokens (etiquetes, admiracions, etc.)\n",
    "- Eliminar els tokens d'una longitud menor de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#lista de stop-words específicos de nuestro corpus (aproximación)\n",
    "stop_words = ['los', 'pero', 'por', 'que', 'una']\n",
    "\n",
    "patron = re.compile('[{}]'.format(re.escape(string.punctuation))) #elimina símbolos de puntuación\n",
    "\n",
    "def clean_text(text, stop_words=stop_words):\n",
    "    \"\"\"Limpiamos las menciones y URL del texto. Luego convertimos en tokens\n",
    "    y eliminamos signos de puntuación.\n",
    "    Dejamos tokens en minúsculas.\n",
    "    Como salida volvemos a convertir los tokens en cadena de texto\"\"\"\n",
    "    text = ___ #elimina menciones y URL\n",
    "    tokens = nlp(text)\n",
    "    tokens = ___ #filtra tokens (puntuaciones, espacios y dígitos)\n",
    "    filtered_tokens = ___ #limpia tokens (signos de puntuación, stop-words y longitud<2)\n",
    "    filtered_text = ___ #juntam,os como string\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "vulnerable-consensus",
   "metadata": {},
   "source": [
    "Aplica la funció a tots els tuits (columna 'content') creant una nova columna 'net' del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['limpio'] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-glory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
