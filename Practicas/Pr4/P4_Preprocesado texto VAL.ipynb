{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dress-auditor",
   "metadata": {},
   "source": [
    "# Pràctica 4 PLN: pre-processat de text i extracció de característiques\n",
    "En aquesta pràctica realitzarem la neteja i pre-processat de diferents conjunts de dades de text.\\\n",
    "Després farem una extracció de característiques com a matriu *sparse* i com a vectors de paraules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "prime-fever",
   "metadata": {},
   "source": [
    "### Noms:\n",
    "Introdueix en aquesta cel·la els noms dels dos integrants del grup:\\\n",
    "*Alumne 1* \\\n",
    "*Alumne 2*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "following-weapon",
   "metadata": {},
   "source": [
    "## Part 1: conjunt de textos de \"mundocine\"\n",
    "En aquest primer conjunt de dades tenim una sèrie de crítiques de pel·lícules de cinema, emmagatzemades en format XML (una crítica per arxiu). Hem preparat una funció de tipus `generator` que processa el directori on estan els arxius de les crítiques i retorna per cada arxiu XML una tupla amb 4 valors:\n",
    " - Nom de la pel·lícula (string)\n",
    " - Resum breu de la crítica (string)\n",
    " - Text de la crítica (*string*)\n",
    " - Valoració de la pel·lícula (*int* d'1 a 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wireless-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from xml.dom.minidom import parseString\n",
    "\n",
    "def parse_folder(path):\n",
    "    \"\"\"generator that reads the contents of XML files in a folder\n",
    "    Returns the <body> of the <review> in each XML file.\n",
    "    XML files encoded as 'latin-1'\"\"\"\n",
    "    for file in sorted([f for f in os.listdir(path) if f.endswith('.xml')],\n",
    "                        key=lambda x: int(re.match(r'\\d+',x).group())):\n",
    "        with open(os.path.join(path, file), encoding='latin-1') as f:\n",
    "            doc=parseString(f.read())\n",
    "\n",
    "            titulo = doc.documentElement.attributes[\"title\"].value\n",
    "\n",
    "            btxt = \"\"\n",
    "            review_bod = doc.getElementsByTagName(\"body\")\n",
    "            if len(review_bod) > 0:\n",
    "                for node in review_bod[0].childNodes:\n",
    "                    if node.nodeType == node.TEXT_NODE:\n",
    "                        btxt += node.data + \" \"\n",
    "\n",
    "            rtxt = \"\"\n",
    "            review_summ = doc.getElementsByTagName(\"summary\")\n",
    "            if len(review_summ) > 0:\n",
    "                for node in review_summ[0].childNodes:\n",
    "                    if node.nodeType == node.TEXT_NODE:\n",
    "                        rtxt += node.data + \" \"\n",
    "                        \n",
    "            rank = int(doc.documentElement.attributes[\"rank\"].value)\n",
    "            \n",
    "            yield titulo, rtxt, btxt, rank\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "automotive-gentleman",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Les crítiques es troben en el directori \"critiques\" (si no tens el directori, descomprimeix l'arxiu \"critiques.zip\" que s'entrega en el material de la pràctica. \\\n",
    "Càrrega la primera crítica del directori usant el mètode `next` sobre la funció `parse_folder` en l'objecte `critica`. Mostra els seus 4 valors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "median-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La guerra de los mundos'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critica = next(parse_folder(\"criticas\"))\n",
    "critica[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "excellent-guitar",
   "metadata": {},
   "source": [
    "## Anàlisi exploratòria\n",
    "Abans de processar el text calcularem una sèrie de paràmetres de cada crítica. \\\n",
    "Per a això processem cada crítica per a i guardarem els resultats en un objecte `DataFrame` de Colles.\\\n",
    "Com a característica de cada crítica extraurem:\n",
    "- Títol de la pel·lícula\n",
    "- Longitud (en caràcters) del resum\n",
    "- Longitud (en caràcters) del text de la crítica\n",
    "- Puntuació de la crítica\n",
    "\n",
    "### Exercici\n",
    "Completa el codi següent per a generar el `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fancy-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#creamos una lista en blanco\n",
    "datos = list()\n",
    "\n",
    "#recorremos las críticas y calculamos sus métricas\n",
    "for c in parse_folder(\"criticas\"):\n",
    "    datos.append({\n",
    "        'título': c[0],\n",
    "        'LongResumen': str(c[1]),\n",
    "        'LongCritica': str(c[2]),\n",
    "        'puntuación': c[3]\n",
    "    })\n",
    "\n",
    "resumen = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outdoor-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>título</th>\n",
       "      <th>LongResumen</th>\n",
       "      <th>LongCritica</th>\n",
       "      <th>puntuación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La guerra de los mundos</td>\n",
       "      <td>Hasta los cojones de los yankis</td>\n",
       "      <td>Cada vez me gusta menos el cine de masas. Las ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stars Wars III La venganza de los Sith</td>\n",
       "      <td>La de los sits y el dar vader</td>\n",
       "      <td>El otro dia fui a ver \"la de los sioux\" como d...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Increibles</td>\n",
       "      <td>¿Por qué las peliculas animadas son mucho mejo...</td>\n",
       "      <td>Es que no la cagan en ninguna, todas las pelis...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spiderman 2</td>\n",
       "      <td>Poniendo a parir una peli que no cuenta nada</td>\n",
       "      <td>Es un dolor esto del cine. Yo ya voy con miedo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La casa de cera</td>\n",
       "      <td>Casquería, terror y cera a partes iguales</td>\n",
       "      <td>Tras una insufrible primera media hora, la cas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>El internado</td>\n",
       "      <td>Bodrio de terror a la francesa</td>\n",
       "      <td>Joder que bodrio de internado. La peli no empi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>La llave del mal</td>\n",
       "      <td>Da más miedo la factura de mi móvil</td>\n",
       "      <td>La llave del mal no es mala película, pero dec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>May</td>\n",
       "      <td>May, ¿quieres ser mi amigo?</td>\n",
       "      <td>\"May, ¿Quieres ser mi amigo?\" es una de esas p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cinderella Man</td>\n",
       "      <td>Cinta maniquea y mil veces vista</td>\n",
       "      <td>Cinderella Man es como comerse un Whopper con ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>La Novia Cadaver</td>\n",
       "      <td>Un calco de Pesadilla antes de Navidad.</td>\n",
       "      <td>Yo creía que iba a ver algo nuevo de Tim Burto...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Harry poter y el caliz de fuego</td>\n",
       "      <td>Interesante adaptación de la novela de Rowling</td>\n",
       "      <td>No. Esta vez no voy a usar una película como p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Match point</td>\n",
       "      <td>Genial Woody Allen</td>\n",
       "      <td>Es sabido que retrata la burguesía como muy po...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>King Kong</td>\n",
       "      <td>El rey Kong</td>\n",
       "      <td>El esfuerzo del director por hacer que esta pe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El jardinero fiel</td>\n",
       "      <td>Tres buenos motivos para ver ésta película</td>\n",
       "      <td>\"El jardinero fiel\" se basa en el libro del mi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Doom</td>\n",
       "      <td>Qué mala es la nostalgia</td>\n",
       "      <td>Ahora es cuando quedo como un friki al decir. ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Las cronicas de Narnia</td>\n",
       "      <td>Buena, pero le falta algo para ser un clásico ...</td>\n",
       "      <td>Unos jovencitos llegan a un fantástico mundo l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Una historia violenta</td>\n",
       "      <td>Una historia realmente violenta</td>\n",
       "      <td>Una Historia Violenta, 2005, es verdaderamente...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Saw 2</td>\n",
       "      <td>Se queda algo lejos de lo que vimos en la prim...</td>\n",
       "      <td>Hace un año llegaba a la pantalla una novedosa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Crash</td>\n",
       "      <td>¿De qué pasta está uno hecho?</td>\n",
       "      <td>Cuando una encuesta quiere saber si un grupo e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jarhead</td>\n",
       "      <td>Una de las mejores películas anti-bélicas desd...</td>\n",
       "      <td>La última película de Sam Mendes (ganador del ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Memorias de una Geisha</td>\n",
       "      <td>En realidad, es una historia de amor más que u...</td>\n",
       "      <td>El cine asiático se ha convertido ya en lo que...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brokeback mountain</td>\n",
       "      <td>La película más sobrevalorada que ha dado el c...</td>\n",
       "      <td>Por fin he podido ver \"Brokeback Mountain\", la...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Alone in the dark</td>\n",
       "      <td>Efectillos especiales sin guión, y acción sin ...</td>\n",
       "      <td>Advertencia a todos mis lectores, no vayan al ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Munich</td>\n",
       "      <td>Demasiado superficial, simplista y didáctica</td>\n",
       "      <td>La nueva película de Steven Spielberg es de es...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Terror en la niebla</td>\n",
       "      <td>Un enorme bodrio, lleno de tonterías</td>\n",
       "      <td>Otro remake americano que se estrena entre nos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Secretos de familia</td>\n",
       "      <td>Por fin Rowan haciendo un papel distinto a Mr....</td>\n",
       "      <td>Rowan Atkinson protagoniza esta comedia al más...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Underworld evolution</td>\n",
       "      <td>Si eres de los que disfrutaste con la primera ...</td>\n",
       "      <td>No entraremos mucho en detalles sobre el hilo ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lutero</td>\n",
       "      <td>Desde la más profunda indiferencia hasta el so...</td>\n",
       "      <td>Parece que, de un tiempo a aquí, el narrar la ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Camaron</td>\n",
       "      <td>Me dió muy buen rollo</td>\n",
       "      <td>La película trata sobre la vida de Jose Monge,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    título  \\\n",
       "0                  La guerra de los mundos   \n",
       "1   Stars Wars III La venganza de los Sith   \n",
       "2                           Los Increibles   \n",
       "3                              Spiderman 2   \n",
       "4                          La casa de cera   \n",
       "5                             El internado   \n",
       "6                         La llave del mal   \n",
       "7                                      May   \n",
       "8                           Cinderella Man   \n",
       "9                         La Novia Cadaver   \n",
       "10         Harry poter y el caliz de fuego   \n",
       "11                             Match point   \n",
       "12                               King Kong   \n",
       "13                       El jardinero fiel   \n",
       "14                                    Doom   \n",
       "15                  Las cronicas de Narnia   \n",
       "16                   Una historia violenta   \n",
       "17                                   Saw 2   \n",
       "18                                   Crash   \n",
       "19                                 Jarhead   \n",
       "20                  Memorias de una Geisha   \n",
       "21                      Brokeback mountain   \n",
       "22                       Alone in the dark   \n",
       "23                                  Munich   \n",
       "24                     Terror en la niebla   \n",
       "25                     Secretos de familia   \n",
       "26                    Underworld evolution   \n",
       "27                                  Lutero   \n",
       "28                                 Camaron   \n",
       "\n",
       "                                          LongResumen  \\\n",
       "0                    Hasta los cojones de los yankis    \n",
       "1                      La de los sits y el dar vader    \n",
       "2   ¿Por qué las peliculas animadas son mucho mejo...   \n",
       "3       Poniendo a parir una peli que no cuenta nada    \n",
       "4          Casquería, terror y cera a partes iguales    \n",
       "5                     Bodrio de terror a la francesa    \n",
       "6                Da más miedo la factura de mi móvil    \n",
       "7                        May, ¿quieres ser mi amigo?    \n",
       "8                   Cinta maniquea y mil veces vista    \n",
       "9            Un calco de Pesadilla antes de Navidad.    \n",
       "10    Interesante adaptación de la novela de Rowling    \n",
       "11                                Genial Woody Allen    \n",
       "12                                       El rey Kong    \n",
       "13        Tres buenos motivos para ver ésta película    \n",
       "14                          Qué mala es la nostalgia    \n",
       "15  Buena, pero le falta algo para ser un clásico ...   \n",
       "16                   Una historia realmente violenta    \n",
       "17  Se queda algo lejos de lo que vimos en la prim...   \n",
       "18                     ¿De qué pasta está uno hecho?    \n",
       "19  Una de las mejores películas anti-bélicas desd...   \n",
       "20  En realidad, es una historia de amor más que u...   \n",
       "21  La película más sobrevalorada que ha dado el c...   \n",
       "22  Efectillos especiales sin guión, y acción sin ...   \n",
       "23      Demasiado superficial, simplista y didáctica    \n",
       "24              Un enorme bodrio, lleno de tonterías    \n",
       "25  Por fin Rowan haciendo un papel distinto a Mr....   \n",
       "26  Si eres de los que disfrutaste con la primera ...   \n",
       "27  Desde la más profunda indiferencia hasta el so...   \n",
       "28                             Me dió muy buen rollo    \n",
       "\n",
       "                                          LongCritica  puntuación  \n",
       "0   Cada vez me gusta menos el cine de masas. Las ...           1  \n",
       "1   El otro dia fui a ver \"la de los sioux\" como d...           3  \n",
       "2   Es que no la cagan en ninguna, todas las pelis...           5  \n",
       "3   Es un dolor esto del cine. Yo ya voy con miedo...           2  \n",
       "4   Tras una insufrible primera media hora, la cas...           2  \n",
       "5   Joder que bodrio de internado. La peli no empi...           2  \n",
       "6   La llave del mal no es mala película, pero dec...           3  \n",
       "7   \"May, ¿Quieres ser mi amigo?\" es una de esas p...           4  \n",
       "8   Cinderella Man es como comerse un Whopper con ...           2  \n",
       "9   Yo creía que iba a ver algo nuevo de Tim Burto...           3  \n",
       "10  No. Esta vez no voy a usar una película como p...           4  \n",
       "11  Es sabido que retrata la burguesía como muy po...           5  \n",
       "12  El esfuerzo del director por hacer que esta pe...           5  \n",
       "13  \"El jardinero fiel\" se basa en el libro del mi...           4  \n",
       "14  Ahora es cuando quedo como un friki al decir. ...           3  \n",
       "15  Unos jovencitos llegan a un fantástico mundo l...           3  \n",
       "16  Una Historia Violenta, 2005, es verdaderamente...           2  \n",
       "17  Hace un año llegaba a la pantalla una novedosa...           3  \n",
       "18  Cuando una encuesta quiere saber si un grupo e...           3  \n",
       "19  La última película de Sam Mendes (ganador del ...           5  \n",
       "20  El cine asiático se ha convertido ya en lo que...           3  \n",
       "21  Por fin he podido ver \"Brokeback Mountain\", la...           2  \n",
       "22  Advertencia a todos mis lectores, no vayan al ...           1  \n",
       "23  La nueva película de Steven Spielberg es de es...           2  \n",
       "24  Otro remake americano que se estrena entre nos...           1  \n",
       "25  Rowan Atkinson protagoniza esta comedia al más...           2  \n",
       "26  No entraremos mucho en detalles sobre el hilo ...           3  \n",
       "27  Parece que, de un tiempo a aquí, el narrar la ...           2  \n",
       "28  La película trata sobre la vida de Jose Monge,...           3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cordless-combat",
   "metadata": {},
   "source": [
    "## Neteja de text\n",
    "Prepararem aquest conjunt de textos per a entrenar un model per a predir la puntuació de cada crítica a partir del text de la crítica.\\\n",
    "Realitzarem el següent processament:\n",
    "- Separar el text en *tokens*\n",
    "- Eliminar els *tokens* de tipus *stop-word*, signes de puntuació o espais\n",
    "- Convertir les entitats de tipus `PER` al token *persona*\n",
    "- Lematizar el text\n",
    "\n",
    "### Exercici\n",
    "Completa el codi següent per a realitzar aquestes funcions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decreased-injection",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1800721667.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    tokens = #devuelve los tokens que cumplen las condiciones\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "#definimos función de normalizado\n",
    "def normaliza(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens = #devuelve los tokens que cumplen las condiciones\n",
    "    palabras = []\n",
    "    for t in tokens:\n",
    "        if t.ent_iob_=='B' and t.ent_type_=='PER':\n",
    "            palabras.append('persona')\n",
    "        elif t.ent_iob_=='I' and t.ent_type_=='PER':\n",
    "            continue\n",
    "        else:\n",
    "            palabras.append(_._____) #si no es PER añadimos el lema\n",
    "    salida = #junta todos los tokens en un string\n",
    "    \n",
    "    return salida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "injured-softball",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament en la crítica prèviament descarregada (variable `critica`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "normaliza(____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beneficial-arkansas",
   "metadata": {},
   "source": [
    "### Possibles millores sobre el processament\n",
    "Observem els següents problemes:\n",
    "- Algunes paraules no se separen correctament perquè en el text original estan unides per signes de puntuació.\n",
    "- La llista de *stop-words* de spaCy no conté 'a','e','i'.\n",
    "- Alguns lemes mantenen les majúscules.\\\n",
    "\n",
    "Redefinim la funció de normalització per a corregir això:\n",
    "- Introduïm un espai després de determinats signes de puntuació (\".\", \"?\") perquè la divisió en tokens siga correcta\n",
    "- Filtrem els *tokens* amb una longitud d'1\n",
    "- Passem a minúscules el lema de cada token\n",
    "\n",
    "Completa la funció per a realitzar aquestes correccions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_bis(texto):\n",
    "    texto = re.sub(r\"___\", r\"___\", texto) #añadimos un espacio después de \".\" y \"?\"\n",
    "    doc = nlp(texto)\n",
    "    tokens = #filtramos los tokens que nos interesan\n",
    "    palabras = []\n",
    "    for t in tokens:\n",
    "        if t.ent_iob_=='B' and t.ent_type_=='PER':\n",
    "            palabras.append('persona')\n",
    "        elif t.ent_iob_=='I' and t.ent_type_=='PER':\n",
    "            continue\n",
    "        else:\n",
    "            palabras.append(___) #añadimos lema en minúsculas\n",
    "    salida = #junta todos los tokens en un string\n",
    "    \n",
    "    return salida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "younger-running",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament en la crítica prèviament descarregada (variable `critica`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "normaliza_bis(____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "funny-parcel",
   "metadata": {},
   "source": [
    "### Anàlisi morfològica\n",
    "En una crítica té molta importància els adjectius utilitzats.\\\n",
    "Crea una funció per a filtrar només els adjectius utilitzats en cada crítica (utilitza el lema de cada adjectiu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_adj(texto):\n",
    "    texto = re.sub(___, ___, texto) #separamos . y ?\n",
    "    doc = nlp(texto)\n",
    "    tokens = #obtenemos lema de todos los tokens de tipo ADJ\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1e902",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament en la crítica prèviament descarregada (variable `critica`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraer_adj(____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "limited-integrity",
   "metadata": {},
   "source": [
    "### Processament de tot el conjunt de dades\n",
    "Aplicarem aquestes funcions en bloc a tot el conjunt de dades. \\\n",
    "En aquesta ocasió, no farem res amb el text normalitzat sinó que només ho aplicarem per a calcular el núm. de paraules i el núm. d'adjectius de cada crítica.\n",
    "\n",
    "### Exercici\n",
    "Completa el codi següent:\\\n",
    "Nota: tingues en compte que per a comptar paraules has de dividir el *string* en espais i comptar el núm. d'elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una lista en blanco\n",
    "datos = []\n",
    "\n",
    "#recorremos las críticas y calculamos sus métricas\n",
    "for c in parse_folder(\"criticas\"):\n",
    "    datos.append({\n",
    "        'título': ___,\n",
    "        'LongResumen': ___,\n",
    "        'LongCritica': ___,\n",
    "        'NumPalabras': ___,\n",
    "        'NumAdj': ___,\n",
    "        'puntuación': c[3]\n",
    "    })\n",
    "\n",
    "resumen = pd.DataFrame(datos)\n",
    "resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "laden-special",
   "metadata": {},
   "source": [
    "## Part 2: Extracció de característiques *sparse*\n",
    "Anem a calcules les matrius de característiques *bag-of-words* i *tfidf* del conjunt de textos anterior.\\\n",
    "Usarem la llibreria `scikit-learn` per a vectorizar els documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para no tener que cargar todas las críticas en memoria,\n",
    "#creamos un generador que devuelve iterativamente el\n",
    "#texto procesado de cada crítica\n",
    "\n",
    "def generaCritica(criticas):\n",
    "    \"\"\"Función de tipo generator que devuelve el\n",
    "    texto normalizado de cada crítica.\n",
    "    Entrada:\n",
    "    criticas: objeto 'parse_folder' que itera\n",
    "    sobre el directio de las críticas\n",
    "    Salida:\n",
    "    texto normalizado de cada crítica\"\"\"\n",
    "    for c in criticas:\n",
    "        yield normaliza_bis(c[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "young-receptor",
   "metadata": {},
   "source": [
    "Comprova el seu funcionament generant el text normalitzat de la primera crítica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(generaCritica(____(____)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adjusted-administration",
   "metadata": {},
   "source": [
    "Vectorizem tot el conjunt de dades usant les funcions de `scikit-learn`.\\\n",
    "Aquestes funcions admeten un objecte `generator` com a argument d'entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "\n",
    "criticas = #creamos el objeto generador\n",
    "BoW_criticas = #entrena y transforma con el corpus de críticas\n",
    "BoW_criticas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stock-wings",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Genera diferents variants de matrius de característiques per al conjunt de les crítiques. Prova amb:\n",
    "- Matriu TF-IDF\n",
    "- Matriu BoW amb unigrames i bigrames\n",
    "- Matriu TF-IDF eliminant les paraules menys freqüents i les més freqüents (mínim de 2 i màxim de 5 documents)\n",
    "- Mostra quines són les paraules més freqüents eliminades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz BoW con unigramas y bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz TF-IDF con min_df=1 y max_df=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras más frecuentes a eliminar\n",
    "#aparecen en el atributo 'stop_words_' del vectorizador"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "primary-intention",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "Ara calcularem els *word vectors* de les paraules del nostre conjunt de dades, usant la classe `word2vec` de la llibreria `gensim`.\\\n",
    "Aquesta llibreria accepta com a argument d'entrada un objecte `iterador` que generarà el text pre-processament de la següent crítica en la seqüència.\\\n",
    "Usarem les funcions de pre-processament de la llibreria `gensim`.\\\n",
    "Primer definim un objecte de tipus `iterator` per a recórrer les crítiques. Es diferencia d'un simple `generator` que es pot reiniciar la generació de la seqüència (necessari per al model `word2vec`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "        \n",
    "class PreprocesaCriticas(object):\n",
    "    \"\"\"Pre-procesa el corpus de críticas con la función 'simple_preprocess'\n",
    "    de la librería gensim\n",
    "    Entrada: directorio de críticas\n",
    "    Salida: iterador sobre las críticas (como lista de tokens)\"\"\"\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for c in parse_folder(self.dirname):\n",
    "            yield simple_preprocess(c[2], deacc=True, min_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciamos un objeto para nuestro directorio\n",
    "criticas = PreprocesaCriticas(____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pending-passion",
   "metadata": {},
   "source": [
    "Per a provar el seu funcionament amb la primera crítica el convertim en iterable i usem el mètode `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "realistic-holiday",
   "metadata": {},
   "source": [
    "Al contrari que l'objecte generat amb la funció `generaCriticas` l'objecte de `PreprocesaCriticas` es reinicia cada vegada que iterem. \\\n",
    "Calculem els vectors de paraules de tot el corpus amb el model `word2vec` que accepta com a argument d'entrada un objecte de tipus `iterator` com el creat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cálculo de los vectores de palabras\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(___, #iterador con los documentos\n",
    "                               size=10,          #tamaño del vector\n",
    "                               window=5,         #nº de términos adyacentes que usamos para el cálculo\n",
    "                               min_count=5,      #nº mínimo de apariciones del término para contarlo\n",
    "                               iter=100\n",
    "                              )\n",
    "\n",
    "#una vez entrenado el modelo nos quedamos con los vectores calculados\n",
    "#si no se van a actualizar los vectores con nuevos documentos\n",
    "model = model.wv\n",
    "len(model.vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "chronic-greensboro",
   "metadata": {},
   "source": [
    "Seleccionem aleatòriament 25 paraules del conjunt calculat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "palabras_sample = np.random.choice(model.index2word, 25, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "superb-terry",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Comprova com funciona el model buscant les paraules més similars semànticament a \"trama\", \"peli\" i \"pelicula\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras similares a 'trama'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras similares a 'peli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "#palabras similares a 'pelicula'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "circular-wheat",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Veurem la influència del preprocessament. Per a això alimentarem el model amb les crítiques *preprocesadas amb la funció de normalització sobre `spaCy` (que produeix text lematizat i amb un altre filtrat).\\\n",
    "Per a això cal re-definir l'objecte `iterador` sobre el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparamos con un modelo que use el preprocesado de spaCy\n",
    "        \n",
    "class PreprocesaCriticasSpacy(object):\n",
    "    \"\"\"Pre-procesa el corpus de críticas con la función de normalización\n",
    "    definida con la librería spaCy\n",
    "    Entrada: directorio de críticas\n",
    "    Salida: iterador sobre las críticas (como lista de tokens)\"\"\"\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for c in parse_folder(self.dirname):\n",
    "            yield ________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pointed-vault",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Instància aquesta nova classe per al directori de les crítiques en l'objecte `critiques_spacy` i comprova el seu funcionament sobre la primera crítica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticas_spacy = PreprocesaCriticasSpacy(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba a generar la primera crítica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "furnished-serial",
   "metadata": {},
   "source": [
    "Calcula el model de vectors de paraules amb aquest nou *pre-processat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSpacy = Word2Vec(_____, #iterador con los documentos\n",
    "                               size=10,          #tamaño del vector\n",
    "                               window=5,         #nº de términos adyacentes que usamos para el cálculo\n",
    "                               min_count=5,      #nº mínimo de apariciones del término para contarlo\n",
    "                               iter=100\n",
    "                              )\n",
    "\n",
    "#una vez entrenado el modelo nos quedamos con los vectores calculados\n",
    "#si no se van a actualizar los vectores con nuevos documentos\n",
    "modelSpacy = modelSpacy.wv\n",
    "len(modelSpacy.vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "weighted-bracelet",
   "metadata": {},
   "source": [
    "### Pregunta\n",
    "per què el nou model té un vocabulari amb molts menys termes que el model anterior?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sound-drawing",
   "metadata": {},
   "source": [
    "### Visualització de word vectors\n",
    "Usem una reducció de dimensionalitat t-SNE per a visualitzar un grup de paraules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "palabras_vectors = model[model.index2word]\n",
    "\n",
    "#seleccinamos unos pocos términos para visualizarlos entre el conjunto\n",
    "random_idx = np.random.randint(len(model.index2word), size=5)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=250, perplexity=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(palabras_vectors)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='steelblue', alpha=0.1)\n",
    "\n",
    "labels = np.array(model.index2word)[random_idx]\n",
    "\n",
    "\n",
    "T_labels = T[random_idx,:]\n",
    "\n",
    "plt.scatter(T_labels[:, 0], T_labels[:, 1], c='lime', edgecolors='darkgreen')\n",
    "for label, x, y in zip(labels, T_labels[:, 0], T_labels[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "advance-success",
   "metadata": {},
   "source": [
    "Ara carregarem els vectors per a les mateixes paraules amb el model pre-entrenat GloVe de `spaCy` per a comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_vectors = [nlp.vocab[t].vector for t in model.index2word]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=250, perplexity=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(palabras_vectors)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c='steelblue', alpha=0.1)\n",
    "\n",
    "labels = np.array(model.index2word)[random_idx]\n",
    "\n",
    "\n",
    "T_labels = T[random_idx,:]\n",
    "\n",
    "plt.scatter(T_labels[:, 0], T_labels[:, 1], c='lime', edgecolors='darkgreen')\n",
    "for label, x, y in zip(labels, T_labels[:, 0], T_labels[:, 1]):\n",
    "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "outdoor-flight",
   "metadata": {},
   "source": [
    "## Part 3: Conjunt de Tuits en espanyol\n",
    "Anem a pre-processar un conjunt de tuits en espanyol etiquetatges amb la seua polaritat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Leemos los datos\n",
    "df = pd.read_csv('tweets_all.csv', index_col=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "incredible-boating",
   "metadata": {},
   "source": [
    "### Exercici\n",
    "Defineix una funció de normalització que faça les següents tasques:\n",
    "- Eliminar esments i URL mitjançant un patró RegEx\n",
    "- Separar el text en *tokens* convertint-los a minúscules, eliminant els que siguen signes de puntuació, espais o dígits\n",
    "- Eliminar els stop-words d'una llista pròpia passada com a argument\n",
    "- Eliminar els símbols de puntuació dels tokens (etiquetes, admiracions, etc.)\n",
    "- Eliminar els tokens d'una longitud menor de 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#lista de stop-words específicos de nuestro corpus (aproximación)\n",
    "stop_words = ['los', 'pero', 'por', 'que', 'una']\n",
    "\n",
    "patron = re.compile('[{}]'.format(re.escape(string.punctuation))) #elimina símbolos de puntuación\n",
    "\n",
    "def clean_text(text, stop_words=stop_words):\n",
    "    \"\"\"Limpiamos las menciones y URL del texto. Luego convertimos en tokens\n",
    "    y eliminamos signos de puntuación.\n",
    "    Dejamos tokens en minúsculas.\n",
    "    Como salida volvemos a convertir los tokens en cadena de texto\"\"\"\n",
    "    text = ___ #elimina menciones y URL\n",
    "    tokens = nlp(text)\n",
    "    tokens = ___ #filtra tokens (puntuaciones, espacios y dígitos)\n",
    "    filtered_tokens = ___ #limpia tokens (signos de puntuación, stop-words y longitud<2)\n",
    "    filtered_text = ___ #juntam,os como string\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "vulnerable-consensus",
   "metadata": {},
   "source": [
    "Aplica la funció a tots els tuits (columna 'content') creant una nova columna 'net' del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['limpio'] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-glory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
