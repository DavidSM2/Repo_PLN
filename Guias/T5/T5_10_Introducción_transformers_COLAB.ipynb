{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3va2amFiOlI"
      },
      "source": [
        "# Introducci√≥n a la librer√≠a ü§ó Transformers\n",
        "Este notebook es una demostraci√≥n de las tareas que se pueden realizar con la librer√≠a ü§ó *transformers* de [Hugging face](https://huggingface.co)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifZpl_EQit3X"
      },
      "outputs": [],
      "source": [
        "#instalamos la librer√≠a\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw763hjWjHjO"
      },
      "source": [
        "## Uso de tareas con `pipeline`\n",
        "La manera m√°s directa de usar una tarea pre-entrenada es mediante un `pipeline`. Transformers tiene tareas pre-entrenadas para:\n",
        "- Sentiment analysis: is a text positive or negative?\n",
        "- Text generation (in English): provide a prompt and the model will generate what follows.\n",
        "- Name entity recognition (NER): in an input sentence, label each word with the entity it represents (person, place,\n",
        "  etc.)\n",
        "- Question answering: provide the model with some context and a question, extract the answer from the context.\n",
        "- Filling masked text: given a text with masked words (e.g., replaced by `[MASK]`), fill the blanks.\n",
        "- Summarization: generate a summary of a long text.\n",
        "- Translation: translate a text in another language.\n",
        "- Feature extraction: return a tensor representation of the text.  \n",
        "\n",
        "Primero importamos la clase `pipeline` antes de poder usarla:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddHA8PCC08ZO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md32CCdENHX7"
      },
      "source": [
        "### An√°lisis de sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U45nyFm-jYAD"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('sentiment-analysis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LIV-v9TjvPn"
      },
      "source": [
        "Una vez instanciado el modelo, el uso es casi inmediato:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtjCnY4ojsAS"
      },
      "outputs": [],
      "source": [
        "classifier('We are very happy to show you the ü§ó Transformers library.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBTVdB6Tj57I"
      },
      "source": [
        "Podemos elegir cualquier modelo pre-entrenado del [model hub](https://huggingface.co/models) de HugginFace. Por ejemplo el modelo `\"nlptown/bert-base-multilingual-uncased-sentiment\"` est√° pre-entrenado en varios idiomas, entre ellos el espa√±ol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbF1JVrsj4p1"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPTd2P4Mklhc"
      },
      "outputs": [],
      "source": [
        "classifier('Me encanta el helado de vainilla')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUtKB_5tkuko"
      },
      "outputs": [],
      "source": [
        "classifier('I hate chocolate ice cream')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(['Odio el helado de chocolate', 'Me encanta el helado de vainilla'])"
      ],
      "metadata": {
        "id": "Tl5-0tSWA8da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jOWmoCclJhQ"
      },
      "source": [
        "### Zero-shot classification\n",
        "Con esta tarea podemos clasificar un texto sin necesidad de etiquetar un conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZbirwEik1u1"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gstSPzqWlnxg"
      },
      "source": [
        "### Generaci√≥n de texto\n",
        "Usando un modelo generativo (de tipo auto-regresivo) podemos generar un texto a partir de una semilla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7-5KY6-lWla"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this tutorial, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ_2D2rul1QD"
      },
      "outputs": [],
      "source": [
        "output = generator(\"In this tutorial, we will teach you how to\", num_return_sequences=2)\n",
        "print(output[0]['generated_text'])\n",
        "print(output[1]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjn_Z4denAfR"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(\"text-generation\", model=\"mrm8488/spanish-gpt2\")\n",
        "generator(\"Me llamo Joan y me gusta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6jnFE7ONlKl"
      },
      "source": [
        "### Mask filling\n",
        "Esta tarea consiste en rellenar los huecos en medio de una frase. Esta es la tarea con la que se entrenan los modelos de lenguaje de los *transformers*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4y-bKCFN9z8"
      },
      "outputs": [],
      "source": [
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"I went to a japanese <mask> to eat some <mask> with cheese.\", top_k=1)"
      ],
      "metadata": {
        "id": "6trB8N_DHuH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQzqeHbJvvL8"
      },
      "source": [
        "### Named Entity Recognition\n",
        "En esta tarea se etiqueta cada *token* seg√∫n su pertenencia a una entidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tOn5TM2vs0s"
      },
      "outputs": [],
      "source": [
        "ner = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TURfU5E1zL0x"
      },
      "outputs": [],
      "source": [
        "#probar con aggregation_strategy=\"none\" (default) para ver la etiqueta de cada token con un esquema B-I-O\n",
        "ner = pipeline(\"ner\", aggregation_strategy=\"none\")\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfSy9GpIwMqS"
      },
      "source": [
        "### Sistemas de respuesta autom√°tica (question answering)\n",
        "Esta tarea consiste en responder una pregunta a partir de un contexto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7bxHVxTwFCS"
      },
      "outputs": [],
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n",
        "context = r\"\"\"\n",
        "Joan lives in New York. His friend Antonio lives in Brussels.\n",
        "\"\"\"\n",
        "question_answerer(\n",
        "    question=\"Where does Joan live?\",\n",
        "    context=context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context[34:95]"
      ],
      "metadata": {
        "id": "87KU4rJbKDUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrH7LYQqy4LQ"
      },
      "source": [
        "### Generaci√≥n de res√∫menes (summarization)\n",
        "Esta tarea consiste en generar un resumen corto (abstractivo) a partir de un texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR7Vfh-ByipN"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC_qtAIT0dSO"
      },
      "source": [
        "### Traducci√≥n de texto\n",
        "Se puede usar el modelo por defecto especificando el par de idiomas en el nombre de la tarea, o podemos usar un modelo espec√≠fico del [model hub](https://huggingface.co/models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhCi4UIGzf_B"
      },
      "outputs": [],
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
        "translator(\"Me llamo Joan y soy profesor de universidad.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3l6lver3AN6"
      },
      "source": [
        "## Uso de los modelos\n",
        "Para usar estos modelos en nuestro flujo de trabajo (p. ej. como un modelo de `tensorflow.keras`) lo necesitamos cargar junto a su funci√≥n de tokenizado espec√≠fica.  \n",
        "Por ejemplo, para un modelo de an√°lisis de sentimientos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1Kd8JG60xA3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "nombre_modelo = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "config = AutoConfig.from_pretrained(nombre_modelo)\n",
        "config.output_hidden_states = True\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(nombre_modelo, config=config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(nombre_modelo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSOqywkF3yJh"
      },
      "source": [
        "Para usar el modelo, primero convertimos la entrada en tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZW5b8S03iG9"
      },
      "outputs": [],
      "source": [
        "tf_batch = tokenizer(\n",
        "    [\"We are very happy to show you the ü§ó Transformers library.\", \"We hope you don't hate it.\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9sJUgh_3-UO"
      },
      "outputs": [],
      "source": [
        "#genera un diccionario con 'inputs_ids' y 'attention_mask' para cada texto de entrada\n",
        "for key, value in tf_batch.items():\n",
        "    print(f\"{key}: {value.numpy().tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(tokenizer.convert_ids_to_tokens(tf_batch['input_ids'][0]))"
      ],
      "metadata": {
        "id": "18J1S9n6TYph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujAjpOFF4kZy"
      },
      "source": [
        "Aplicamos el modelo, que devuelve los 'logits' de la √∫ltima capa y las salidas de cada capa intermedia (*embeddings*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLLjxN0n3_-x"
      },
      "outputs": [],
      "source": [
        "tf_outputs = tf_model(tf_batch)\n",
        "tf_outputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tf_outputs.hidden_states) #N¬∫ de capas de atenci√≥n internas del transformer"
      ],
      "metadata": {
        "id": "0pZGLwEICFa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_outputs.hidden_states[0].shape #embeddings de salida de cada capa (n¬™ muestras, n¬∫ tokens, n¬∫ dimensiones)"
      ],
      "metadata": {
        "id": "zmPVzYMYC8AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEWooVRh4yf1"
      },
      "source": [
        "Aplicamos la funci√≥n de activaci√≥n Softmax para obtener las probabilidades normalizadas de cada clase (negativo, positivo) a partir de los logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCh1A7d24j3x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lDaXEry4_j6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTT5QmMrOXKc"
      },
      "source": [
        "## Sesgo de los modelos\n",
        "Los modelos de lenguaje de los *transformers* se han entrenado con grandes cantidades de texto no supervisado, mayoritariamente obtenido de Internet. Por tanto, puede tener sesgos (racismo, sesgo de g√©nero, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqtqsSFkO0L5"
      },
      "outputs": [],
      "source": [
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}