{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador binario\n",
    "Vamos a utilizar Spacy y scikit-learn para clasificar con conjunto de tweets en español como positivos/negativos (análisis de sentimientos)\n",
    "\n",
    "## Carga y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Leemos los datos\n",
    "df = pd.read_csv('tweets_all.csv', index_col=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 1514 tweets, de los cuales hay 637 positivos y 474 negativos. El resto son neutros o no tienen polaridad clasificada.\n",
    "Vamos a entrenar sólo con los positivos y negativos para utilizar un clasificador binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['polarity']=='P') | (df['polarity']=='N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitamos las columnas que no usamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de texto\n",
    "Hacemos un pequeño pre-procesado del texto antes de extraer las características:  \n",
    "- Quitamos las menciones y las URL del texto porque no aportan valor para el análisis de sentimientos.\n",
    "- Los hashtag sí que pueden aportar valor así que simplemente quitamos el #.\n",
    "- Quitamos los signos de puntuación y palabras menores de 3 caracteres.\n",
    "- Por último quitamos todos los símbolos de puntuación del texto (que forman parte de un token).\n",
    "- Lematizamos el texto y lo guardamos en otra columna para comparar resultados del clasificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, spacy\n",
    "nlp=spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de stop-words específicos de nuestro corpus (aproximación)\n",
    "stop_words = ['unos', 'unas', 'algún', 'alguna', 'algunos', 'algunas', 'ese', 'eso', 'así']\n",
    "\n",
    "pattern2 = re.compile('[{}]'.format(re.escape(string.punctuation))) #elimina símbolos de puntuación\n",
    "\n",
    "def clean_text(text, lemas=False):\n",
    "    \"\"\"Limpiamos las menciones y URL del texto. Luego convertimos en tokens\n",
    "    y eliminamos signos de puntuación.\n",
    "    Si lemas=True extraemos el lema, si no dejamos en minúsculas solamente.\n",
    "    Como salida volvemos a convertir los tokens en cadena de texto\"\"\"\n",
    "    text = re.sub(r'@[\\w_]+|https?://[\\w_./]+', '', text) #elimina menciones y URL\n",
    "    tokens = nlp(text)\n",
    "    tokens = [tok.lemma_.lower() if lemas else tok.lower_ for tok in tokens if not tok.is_punct]\n",
    "    filtered_tokens = [pattern2.sub('', tok) for tok in tokens if not (tok in stop_words) and len(tok)>2]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return filtered_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el funcionamiento de estas funciones sobre un tweet de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.content[702])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(clean_text(df.content[702]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original:\\n',df.content[702])\n",
    "print('\\nLimpiado:\\n',clean_text(df.content[702]))\n",
    "print('\\nLematizado:\\n',clean_text(df.content[702], lemas=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos limpieza a todos los tweets del DataFrame y creamos columna nueva con los lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"limpio\"]=df['content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos tweets vacíos después de la limpieza\n",
    "df=df[df.limpio!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemas\"]=df.content.apply(clean_text, lemas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contamos el nº de palabras por tweet\n",
    "df['words'] = [len(t.split(' ')) for t in df.limpio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df['limpio'].apply(lambda t: len(t.split(' '))) #igual que la anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador\n",
    "Vamos a usar la librería scikit-learn para aplicar un clasificador binario sobre la polaridad usando una extracción de características Bag-of-Words (BoW)\n",
    "\n",
    "Primero dividimos en conjunto de entrenamiento y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "# Asignamos un 70% a training y un 30% a test\n",
    "X_train, X_test, y_train, y_test, X_train_lema, X_test_lema = train_test_split(df['limpio'], \n",
    "                                                    df['polarity'],\n",
    "                                                    df['lemas'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Primera entrada de train:\\n', X_train.iloc[0])\n",
    "print('Polaridad:', y_train.iloc[0])\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# aprendemos el modelo CountVectorizer sobre el conjunto de train\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el número de términos distintos que tiene el diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(vect.get_feature_names_out(), 5, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo\n",
    "Vamos a probar un clasificador Logistic Regression de scikit-learn para entrenar nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(solver='liblinear')\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelLR.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train = modelLR.predict(X_train_vectorized)\n",
    "pd.DataFrame({\n",
    "    'texto':X_train,\n",
    "    'polaridad':y_train,\n",
    "    'predicción':prediccion_train\n",
    "}).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_train, prediccion_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación del modelo\n",
    "Para ver el rendimiento del modelo usamos el conjunto de test. Primero transformamos el conjunto de test a su matriz BoW mediante el vectorizador aprendido en TRAIN y aplicamos el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos sobre el conjunto de test\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = modelLR.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el resultado de la predicción y calculamos su precisión con distintas métricas.  \n",
    "Ejemplo de predicción de algunas muestras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'texto':X_test, 'polaridad':y_test, 'predicción':prediccion}).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exactitud del modelo\n",
    "(# predicciones correctas / Total de muestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Exactitud: ', accuracy_score(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión (predicción -columnas- frente a etiquetas reales -filas-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(y_test, prediccion)\n",
    "pd.DataFrame(cm, index=('N_true','P_true'), columns=('N_pred','P_pred'))\n",
    "#filas: True, columnas: Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver un informe más completo del clasificador con la métrica `classification_report`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`precision` es la precisión: TP/(TP+FP) (probabilidad de que un positivo detectado sea un verdadero positivo)  \n",
    "`recall` es la sensibilidad: TP/(TP+FN) (probabilidad de predicción positiva para una muestra positiva)  \n",
    "`support` indica el número de muestras en cada clase en el conjunto de test (suma por filas en la matriz de confusión)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Área bajo la curva ROC:  \n",
    "Para calcular el área bajo la curva ROC (AUC) es necesario obtener la probabilidad de salida del clasificador con `predict_proba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "prediccion_prob = modelLR.predict_proba(vect.transform(X_test))\n",
    "#la primera columna corresponde a la etiqueta 'N'\n",
    "#Es necesario convertir los True Labels a un array lógico (1 para etiqueta N)\n",
    "roc_auc_score((y_test=='N'), prediccion_prob[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos qué palabras son las más relevantes en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los nombres de las características numpy array\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "# Ordenamos los coeficientes del modelo\n",
    "sorted_coef_index = modelLR.coef_[0].argsort()\n",
    "\n",
    "# Listamos los 10 coeficientes menores y mayores\n",
    "print('Menores Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Mayores Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que Naive Bayes mejora al modelo de Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización del código\n",
    "Combinamos la extracción de características y clasificación en un `pipeline` de scikit-learn (https://scikit-learn.org/stable/modules/compose.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vect = CountVectorizer()\n",
    "modelLR = LogisticRegression(solver='liblinear')\n",
    "\n",
    "modelo = make_pipeline(vect, modelLR)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(modelo['countvectorizer'].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivale a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo[0].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivale a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo[1].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros modelos\n",
    "Probamos con los modelos Naïve Bayes y un SVM lineal para ver si mejora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelNB.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelNB.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "modelSVM = SGDClassifier(loss='hinge', max_iter=10000, tol=1e-5)\n",
    "\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelSVM.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelSVM.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con vectores TF-IDF\n",
    "Cambiamos el vectorizador para ver si hay mejoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "modelo = make_pipeline(vect, modelLR)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los nombres de las características numpy array\n",
    "feature_names = np.array(modelo['tfidfvectorizer'].get_feature_names_out())\n",
    "\n",
    "# Ordenamos los coeficientes del modelo\n",
    "sorted_coef_index = modelo['logisticregression'].coef_[0].argsort()\n",
    "\n",
    "# Listamos los 10 coeficientes menores y mayores\n",
    "print('Menores Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Mayores Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otros modelos con TF-IDF\n",
    "Repetimos con los modelos NB y SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = make_pipeline(vect, modelNB)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = make_pipeline(vect, modelSVM)\n",
    "#Entrenamos el modelo con el conjunto de train\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecimos sobre el conjunto de test\n",
    "prediccion = modelo.predict(X_test)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos con texto lematizado\n",
    "Repetimos con el texto lematizado para ver si hay diferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "# Asignamos un 70% a training y un 30% a test\n",
    "X_train_lema, X_test_lema, y_train, y_test = train_test_split(df['lemas'], \n",
    "                                                    df['polarity'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lema.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos BoW con texto lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizamos\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(modelo[0].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-LR\n",
    "modelLR.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelLR.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-NB\n",
    "modelNB.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelNB.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-SVM\n",
    "modelSVM.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelSVM.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los nombres de las características numpy array\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "# Ordenamos los coeficientes del modelo\n",
    "sorted_coef_index = modelLR.coef_[0].argsort()\n",
    "\n",
    "# Listamos los 10 coeficientes menores y mayores\n",
    "print('Menores Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Mayores Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos TF-IDF con texto lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizamos\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-LR\n",
    "modelLR.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelLR.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-NB\n",
    "modelNB.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelNB.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-SVM\n",
    "modelSVM.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelSVM.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos los nombres de las características numpy array\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "# Ordenamos los coeficientes del modelo\n",
    "sorted_coef_index = modelLR.coef_[0].argsort()\n",
    "\n",
    "# Listamos los 10 coeficientes menores y mayores\n",
    "print('Menores Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Mayores Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos n-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizamos\n",
    "vect = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(vect.get_feature_names_out(), 5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos los 3 clasificadores con las características BoW-bigramas\n",
    "modelos = [('Logistic Regression', modelLR),\n",
    "           ('Naive Bayes', modelNB),\n",
    "           ('Linear SVM', modelSVM)]\n",
    "for m, clf in modelos:\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    prediccion = clf.predict(X_test_vectorized)\n",
    "    print(f'Modelo {m}: {accuracy_score(y_test, prediccion):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faltaría probar otras combinaciones:  \n",
    "- TF-IDF con bigramas\n",
    "- Bigramas con texto sin lematizar\n",
    "- Reducción del vocabulario con `min_df` y `max_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quitamos palabras presentes en más del 10% de documentos\n",
    "vect = TfidfVectorizer(max_df=0.1)\n",
    "X_train_vectorized = vect.fit_transform(X_train_lema)\n",
    "X_test_vectorized = vect.transform(X_test_lema)\n",
    "print(len(vect.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos los 3 clasificadores con las características BoW quitando stop-words\n",
    "modelos = [('Logistic Regression', modelLR),\n",
    "           ('Naive Bayes', modelNB),\n",
    "           ('Linear SVM', modelSVM)]\n",
    "for m, clf in modelos:\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    prediccion = clf.predict(X_test_vectorized)\n",
    "    print(f'Modelo {m}: {accuracy_score(y_test, prediccion):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo sin preprocesado\n",
    "Por comparar probamos un modelo Bow-LR sin pre-procesar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], \n",
    "                                                    df['polarity'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizamos\n",
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vectorized = vect.fit_transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo BoW-LR\n",
    "modelLR.fit(X_train_vectorized, y_train)\n",
    "prediccion = modelLR.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baja la exactitud del modelo de un 76% a un 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con word embeddings\n",
    "Ahora vamos a usar como espacio de características los *word vectors* de las palabras de nuestro corpus.  \n",
    "Como cada palabra tiene un vector de longitud fija, tenemos que obtener un único vector como promedio de todas las palabras del tweet.  \n",
    "En spaCy, el vector de cada palabra es el atributo `vector`.  \n",
    "El atributo `vector` del objeto `Doc` del texto procesado en spaCy contiene el vector promedio de todos los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del vector del modelo `Spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab.vectors_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es el tamaño del vector de cada token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(df.content[1])\n",
    "doc[1].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que coincide con el tamaño del vector del documento entero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este vector corresponde al promedio de los vectores de todos los tokens del documento que tienen un vector definido en `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada vector tiene un tamaño de 50, por tanto hay que crear una matriz de\n",
    "#tamaño (nº documentos,50) para guardar el promedio de los vectores de cada tweet\n",
    "#y guardar en cada fila el correspondiente vector promedio\n",
    "word_embeddings=np.zeros((len(df), nlp.vocab.vectors_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy ya calcula el promedio de los vectores de un documento en Doc.vector\n",
    "vectors = [nlp(tweet).vector for tweet in df.limpio]\n",
    "for i,vector in enumerate(vectors):\n",
    "    word_embeddings[i,:]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos los conjuntos de entrenamiento con word embeddings de cada tweet y volvemos a aplicar los mismos clasificadores de antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(word_embeddings, \n",
    "                                                    df['polarity'], \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos un clasificador a esta matriz de características. En este caso la matriz conviene valores decimales, por lo que el clasificador `MultinomialNB` se tiene que sustituir por un `GaussianNB` para usar un modelo Naïve Bayes, pero también podemos probar otros modelos más complejos (p. ej. un SVM con un kernel RFB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamos clasificadores con modelos word embeddings\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelos = [('Logistic Regression', modelLR),\n",
    "           ('Naive Bayes', GaussianNB()),\n",
    "           ('Linear SVM', modelSVM),\n",
    "           ('RFB SVM', SVC(gamma='scale', C=2))]\n",
    "\n",
    "for m, clf in modelos:\n",
    "    #entrenamos sobre train\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predecimos sobre el conjunto de test\n",
    "    prediccion = clf.predict(X_test)\n",
    "    print(f'Modelo {m}: {accuracy_score(y_test, prediccion):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos con word embedding promediado para todo el tweet funcionan un poco peor que modelos más simples (BoW, TF-IDF). Para usar word embeddings conviene irse a un modelo secuencial (por ejemplo con LSTM), para lo que es necesario entrenar con un conjunto de datos mucho mayor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "974d86b888590d91c91725277f46e2331e9f38bd583c386dd56dd3384a234a0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
