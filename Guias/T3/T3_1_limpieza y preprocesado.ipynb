{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "metric-breathing",
   "metadata": {},
   "source": [
    "### División de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"La gata de Juan es blanca.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.text for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c6ebc-17cc-4c5f-8527-1329dc1d762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.lower_ for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"la vaca come hierba. El perro come longanizas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s.text for s in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-termination",
   "metadata": {},
   "source": [
    "### Limpieza de acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "data = 'Sómě Áccěntěd tëxt'\n",
    "normal = unicodedata.normalize('NFKD', data).encode('ASCII', 'ignore')\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_accents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e58bf5-9631-4bba-abd2-ff7e782e3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_accents(data) + ' adiós'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd9685-598d-4080-8dd4-88fe29ee5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal + ' adiós'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import deaccent\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.deaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaccent(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(deaccent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-ebony",
   "metadata": {},
   "source": [
    "### Limpieza de caracteres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pat = '[{}]'.format(re.escape(string.punctuation))\n",
    "    return re.sub(pat, '', text)\n",
    " \n",
    "texto = \"007 Not sure@,of course if this % was #fun! 558923 What do# you think** of it.? $500USD!\"\n",
    "remove_special_characters(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "'[{}]'.format(re.escape(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da99377-78c8-4e87-ab9f-93938ac5f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([t for t in nlp(texto)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628c45e-91e5-46ee-a478-b3ca728a2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([t for t in nlp(remove_special_characters(texto))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-seventh",
   "metadata": {},
   "source": [
    "### Expandir contracciones\n",
    "hay que instalar la librería https://github.com/kootenpv/contractions con ```pip install contractions```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "contractions.fix(\"you're happy now, aren't you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp_en(\"you're happy now, aren't you?\")\n",
    "[t for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-quarterly",
   "metadata": {},
   "source": [
    "### Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy    \n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "print(len(nlp.Defaults.stop_words))\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed0d9446",
   "metadata": {},
   "source": [
    "Cuidado con las negaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "'no' in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "'tí' in nlp.Defaults.stop_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ede60883",
   "metadata": {},
   "source": [
    "Los stop-words tienen el atributo `is_stop` a `TRUE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hoy no me apetece ir a dar clase\")\n",
    "datos = map(lambda t: {'token': t.orth_,\n",
    "                       'STOP': t.is_stop},\n",
    "                        doc)\n",
    "\n",
    "pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c930e-3572-4397-8e2a-5010b2677492",
   "metadata": {},
   "outputs": [],
   "source": [
    "'todavia' in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830daaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'usáis' in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ed5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#en cambio la palabra incorrecta\n",
    "'usais' in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos añadir o quitar palabras de la lista\n",
    "\n",
    "#añadir\n",
    "nlp.Defaults.stop_words.add(\"my_new_stopword\")\n",
    "nlp.Defaults.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\"}\n",
    "\n",
    "#quitar\n",
    "nlp.Defaults.stop_words.remove(\"usais\")\n",
    "nlp.Defaults.stop_words -= {\"tuya\", \"mia\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"usais\" in nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim\n",
    "gensim_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
    "text = f\"The first time I saw Catherine she was wearing a vivid crimson dress and was nervously \" \\\n",
    "       f\"leafing through a magazine in my waiting room.\"\n",
    "print(f\"Original Text : {text}\")\n",
    "print(f\"Text without stopwords : {remove_stopwords(text.lower())}\")\n",
    "print(f\"Total count of stopwords in Gensim is {len(list(gensim_stopwords))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-miller",
   "metadata": {},
   "source": [
    "### Corrección ortográfica\n",
    "Librería `spellchecker`. Instalamos con\n",
    "```pip install pyspellchecker```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(language='es')  # Spanish dictionary\n",
    "print(f\"Hay {spell.word_frequency._unique_words} palabras en el diccionario\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.correction('mañnaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.candidates('mañnaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si una palabra está en el diccionario devuelve su frecuencia relativa:\n",
    "spell['mañana']  #equivale a spell.word_frequency['mañana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell['mañnaa']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1808a39",
   "metadata": {},
   "source": [
    "Si una palabra está en el diccionario, aunque que la frecuencia sea baja no la corregirá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell['mañna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160741b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.correction('mañna')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-singing",
   "metadata": {},
   "source": [
    "### Lematizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(\"el gato es blanco\")\n",
    "[t.lemma_ for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f03fe5-3d2d-4a57-8fff-a992aafe555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"la vaca come hierba. Los perros comen longanizas.\")\n",
    "[s.lemma_ for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"la salida se ha bloqueado. La salida está bloqueada.\")\n",
    "[(t.lemma_, t.pos_) for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-bride",
   "metadata": {},
   "source": [
    "### Funciones de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"@Graffitera23 qué hermoso!,es bueno desviar la\n",
    "mirada al cielo y a las #nubes de vez en cuando, \n",
    "abajo está jodido. Preciosa foto,mil abrazos \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en spacy\n",
    "import re\n",
    "import spacy\n",
    "nlp=spacy.load('es_core_news_sm')\n",
    "               \n",
    "def normalize_document(doc):\n",
    "   # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # quitamos puntuación/espacios y stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if not t.is_stop and not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_document(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-situation",
   "metadata": {},
   "source": [
    "Con esta función no se eliminan los signos de puntuación que no forman un token de manera independiente, debemos hacerlo con un patrón regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "pat  = '[{}]'.format(re.escape(string.punctuation))\n",
    "\n",
    "def normalize_document_remove_punct(doc):\n",
    "   # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # quitamos puntuación/espacios y stopwords\n",
    "    filtered_tokens = [re.sub(pat, ' ', t.lower_) \n",
    "      for t in tokens\n",
    "         if not t.is_stop\n",
    "         and not t.is_punct\n",
    "         and not t.is_space]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_document_remove_punct(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcf907-3558-4e29-8a18-391dac39d860",
   "metadata": {},
   "source": [
    "Con la librería `gensim` tenemos acceso a diversas funciones de normalización que convierten una cadena de texto en un listado de tokens normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess\n",
    "\n",
    "help(simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_preprocess(texto, deacc=True, min_len=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "#https://radimrehurek.com/gensim/utils.html#gensim.utils.tokenize\n",
    "\n",
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tokenize(texto, deacc=True, lowercase=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "#https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string\n",
    "help(preprocess_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(texto) #elimina stop words y deja raíz de las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"<i>Hel 9lo</i> <b>Wo9 rld</b>! Th3     weather_is really g00d today, isn't it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import *\n",
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords, stem_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4aede1-f7a6-4132-8e4d-378eb5f124db",
   "metadata": {},
   "source": [
    "También la librería `textaCy` proporciona diversas funciones de preprocesado (https://textacy.readthedocs.io/en/latest/api_reference/preprocessing.html).  \n",
    "La instalamos con  \n",
    "`conda install -c conda-forge textacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e923a-bd70-4f85-ad19-1e2c17fbeeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy import preprocessing\n",
    "preproc = preprocessing.make_pipeline(\n",
    "     preprocessing.replace.hashtags,\n",
    "     preprocessing.replace.user_handles,\n",
    "     preprocessing.replace.emojis,\n",
    "     preprocessing.remove.accents\n",
    " )\n",
    "preproc(\"Según @valencia, hoy comienzan las #fallas con la primera mascletà 🔥🎇\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e547994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1889f7d8acdc3cacfafa5b333be0ab79c5c49ae12b0b38e71a3abcd28f98edde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
